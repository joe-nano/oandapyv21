{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.family'] = 'IPAPGothic'\n",
    "from oandapyV20 import API\n",
    "from oandapyV20.exceptions import V20Error\n",
    "import oandapyV20.endpoints.instruments as instruments\n",
    "import datetime\n",
    "from statistics import mean\n",
    "from statistics import median\n",
    "import calendar\n",
    "import datetime\n",
    "from math import floor\n",
    "import time\n",
    "import threading\n",
    "import json\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from joblib import dump, load\n",
    "from sklearn import metrics\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import feather\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OANDA API v20の口座IDとAPIトークン\n",
    "accountID = \"101-009-12789646-001\"\n",
    "access_token = \"1ab53171ce4413f408de6da28ea23089-6426c3d3cc947dba212b3766d1be45c6\"\n",
    "# OANDAのデモ口座へのAPI接続\n",
    "api = API(access_token=access_token, environment=\"practice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APIから取得したレートをPandasのDataFrameへ\n",
    "def to_dataframe(r):\n",
    "    data = []\n",
    "    for raw in r.response['candles']:\n",
    "        data.append([raw['time'], raw['volume'], raw['mid']['o'], raw['mid']['h'], raw['mid']['l'], raw['mid']['c']])\n",
    "\n",
    "    # リストからPandas DataFrameへ変換\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = ['Time', 'Volume', 'Open', 'High', 'Low', 'Close']\n",
    "    df['Time'] = pd.to_datetime(df['Time'])\n",
    "    for col in ['Open', 'High', 'Low', 'Close']:\n",
    "        df[col] = df[col].apply(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(count, gran, year, month, day, hour, minute, second):\n",
    "    # OANDA API v20の口座IDとAPIトークン\n",
    "    accountID = \"101-009-12789646-001\"\n",
    "    access_token = \"1ab53171ce4413f408de6da28ea23089-6426c3d3cc947dba212b3766d1be45c6\"\n",
    "    # OANDAのデモ口座へのAPI接続\n",
    "    api = API(access_token=access_token, environment=\"practice\")\n",
    "    fmt = '%Y-%m-%dT%H:%M:00.000000Z'\n",
    "    _from = datetime.datetime(year=year, month=month, day=day,\n",
    "                              hour=hour, minute=minute, second=second).strftime(fmt)\n",
    "    params = {\n",
    "        \"count\": count,\n",
    "        \"granularity\": gran,\n",
    "        'from': _from,\n",
    "#         'dailyAlignment': 0\n",
    "    }\n",
    "    r = instruments.InstrumentsCandles(instrument=\"USD_JPY\", params=params)\n",
    "    api.request(r)\n",
    "    df = to_dataframe(r)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_super(start, end, gran):\n",
    "    # OANDA API v20の口座IDとAPIトークン\n",
    "    accountID = \"101-009-12789646-001\"\n",
    "    access_token = \"1ab53171ce4413f408de6da28ea23089-6426c3d3cc947dba212b3766d1be45c6\"\n",
    "    # OANDAのデモ口座へのAPI接続\n",
    "    api = API(access_token=access_token, environment=\"practice\")\n",
    "    # xxxx-xx-xx～xxxx-xx-xx の期間のデータを取得してデータフレームを返す\n",
    "    s_year, s_month, s_day, s_hour, s_minute, s_second = map(int, start.split('-'))\n",
    "    e_year, e_month, e_day, e_hour, e_minute, e_second = map(int, end.split('-'))\n",
    "    fmt = '%Y-%m-%dT%H:%M:00.000000Z'\n",
    "    from_ = datetime.datetime(year=s_year, month=s_month, day=s_day,\n",
    "                              hour=s_hour, minute=s_minute, second=s_second).strftime(fmt)\n",
    "    to_ = datetime.datetime(year=e_year, month=e_month, day=e_day,\n",
    "                            hour=e_hour, minute=e_minute, second=e_second).strftime(fmt)\n",
    "    df = pd.DataFrame()\n",
    "    # 5000個制限に引っかからなければこっちの処理\n",
    "    try:\n",
    "        params = {\n",
    "            \"granularity\": gran,\n",
    "            'from': from_,\n",
    "            'to': to_\n",
    "        }\n",
    "        r = instruments.InstrumentsCandles(instrument=\"USD_JPY\", params=params)\n",
    "        api.request(r)\n",
    "        df = to_dataframe(r)\n",
    "    # 引っかかればこっちの処理\n",
    "    except:\n",
    "        i = True\n",
    "        while i:\n",
    "            df_tmp = get_data(count=5000, gran=gran, year=s_year, month=s_month, day=s_day,\n",
    "                             hour=s_hour, minute=s_minute, second=s_second)\n",
    "            df = pd.concat([df, df_tmp], ignore_index=True)\n",
    "            index = df_tmp.tail(1).index[0]\n",
    "            s_year = df_tmp.iat[index, 0].year\n",
    "            s_month = df_tmp.iat[index, 0].month\n",
    "            s_day = df_tmp.iat[index, 0].day\n",
    "            s_hour = df_tmp.iat[index, 0].hour\n",
    "            s_minute = (df_tmp.iat[index, 0].minute + 1) % 60\n",
    "            s_second = df_tmp.iat[index, 0].second\n",
    "#             print('{}-{}-{}-{}-{}-{}'.format(s_year, s_month, s_day, s_hour, s_minute, s_second))\n",
    "            # 5000個ずつ取得してエンド超えたら止める\n",
    "            if s_year == e_year:\n",
    "                i = False\n",
    "        # 止めたらはみ出した分をここで切り落とす\n",
    "        for i in range(len(df.index) - 5000, len(df.index)):\n",
    "            if df.iat[i, 0].year == e_year and df.iat[i, 0].month == e_month and df.iat[i, 0].day == e_day:\n",
    "                df = df[0:i]\n",
    "                break\n",
    "    # ボリンジャーバンドを追加\n",
    "    sigma = 1\n",
    "    df['BB20,+{}'.format(sigma)] = df['BB20,-{}'.format(sigma)] = 0\n",
    "    df['BB20,+{}'.format(sigma)] = df['BB20,+{}'.format(sigma)].apply(float)\n",
    "    df['BB20,-{}'.format(sigma)] = df['BB20,-{}'.format(sigma)].apply(float)\n",
    "    for i in range(20, len(df)):\n",
    "        df.iat[i, 6] = round(mean(df['Close'][i-20:i]) + (np.std(df['Close'][i-20:i]) * sigma), 3)\n",
    "        df.iat[i, 7] = round(mean(df['Close'][i-20:i]) - (np.std(df['Close'][i-20:i]) * sigma), 3)\n",
    "    # シグナル追加\n",
    "    df['Lシグナル'] = df['Sシグナル'] = 0\n",
    "    for i in range(len(df)):\n",
    "        if df.iat[i, 6] < df.iat[i, 5]:\n",
    "            df.iat[i, 8] = 1\n",
    "        if df.iat[i, 7] > df.iat[i, 5]:\n",
    "            df.iat[i, 9] = 1\n",
    "    # 移動平均追加\n",
    "    df['SMA20'] = 0\n",
    "    df['SMA20'] = df['SMA20'].apply(float)\n",
    "    for i in range(20, len(df)):\n",
    "        df.iat[i, 10] = round(mean(df['Close'][i-20:i]), 3)\n",
    "    # BB と SMA で参照した最初の分を落とす\n",
    "    df = df[20:]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データ作る関数 (binary用)\n",
    "def get_dataset_bc(df, n, m):\n",
    "    LGB_df = pd.DataFrame()\n",
    "    for i in range(1, n+1):\n",
    "        diff_tmp = df.iloc[:, [2,3,4,5,6,7,10]].diff(i)*100\n",
    "        diff_tmp['Volume'] = df.iloc[:, [1]].shift(i)\n",
    "        diff_tmp['Lシグナル'] = df.iloc[:, [8]].shift(i)\n",
    "        diff_tmp['Sシグナル'] = df.iloc[:, [9]].shift(i)\n",
    "        LGB_df = pd.concat([LGB_df, diff_tmp], axis=1)\n",
    "    LGB_df['y'] = df['Close'].diff(-10)*100\n",
    "    LGB_df = LGB_df[n:(len(LGB_df)-n)]\n",
    "    LGB_df_1 = LGB_df[LGB_df['y'] >= m].assign(target=1)\n",
    "    LGB_df_2 = LGB_df.query('y < {}'.format(m)).assign(target=0)\n",
    "    LGB_df_c = pd.concat([LGB_df_1, LGB_df_2], axis=0)\n",
    "    # LGB_df_c.drop(['y'], axis=1, inplace=True)\n",
    "    # LGB_df_c = LGB_df_c.sample(frac=1, random_state=1729)\n",
    "    LGB_df_c.reset_index(drop=True, inplace=True)\n",
    "    return LGB_df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/df.csv')\n",
    "df = pd.read_csv('data/df_sma.csv')\n",
    "# LGB_df = pd.read_csv('data/LGB_df_BB.csv')\n",
    "# LGB_df = pd.read_csv('data/LGB_df_SMA.csv')\n",
    "# df_10 = pd.read_csv('data/df_10.csv')\n",
    "df_5 = pd.read_csv('data/df_5.csv')\n",
    "df_2017 = pd.read_csv('data/df_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_df_bc = get_dataset_bc(df, 50, 10)\n",
    "# LGB_df_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_df_bc.columns = map(str, range(502))\n",
    "X = LGB_df_bc.drop(['500', '501'], axis=1).to_numpy()\n",
    "y = LGB_df_bc[['501']].to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'seed': 1729,\n",
    "    'learning_rate': 0.05\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KF = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "KF.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8089658538518746\n",
      "0.7988209409417719\n",
      "0.7807959636147674\n",
      "0.7991233388995888\n",
      "0.8056932888011916\n",
      "0.7886183016752675\n",
      "0.7935641659781111\n",
      "0.8050697520276738\n",
      "0.7869136914177702\n",
      "0.7718052312157072\n",
      "mean: 0.7939370528423724\n"
     ]
    }
   ],
   "source": [
    "auc_l = []\n",
    "for train_index, test_index in KF.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    X_train2, X_valid, y_train2, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "    lgb_train = lgb.Dataset(X_train2, y_train2)\n",
    "    lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
    "    LGB = lgb.train(lgbm_params, lgb_train,\n",
    "                    # モデルの評価用データを渡す\n",
    "                    valid_sets=lgb_eval,\n",
    "                    # 最大で 1000 ラウンドまで学習する\n",
    "                    num_boost_round=1000,\n",
    "                    # 10 ラウンド経過しても性能が向上しないときは学習を打ち切る\n",
    "                    early_stopping_rounds=10,\n",
    "                    # うるさいので黙らせる\n",
    "                    verbose_eval = False)\n",
    "    y_pred = LGB.predict(X_test, num_iteration=LGB.best_iteration)\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    print(auc)\n",
    "    auc_l.append(auc)\n",
    "print('mean: {}'.format(mean(auc_l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 KFold\n",
    "# mean: 0.7836842971095238\n",
    "# 10 KFold seed = 1729\n",
    "# mean: 0.7936685896273451\n",
    "# 10 KFold seed = 42\n",
    "# mean: 0.7939370528423724"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SKF = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "SKF.get_n_splits(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8005931497085041\n",
      "0.7763550660619003\n",
      "0.8065124482201068\n",
      "0.7859698989810447\n",
      "0.8031150237203107\n",
      "0.8092663421589752\n",
      "0.783071724506159\n",
      "0.7747727567083356\n",
      "0.794882625721018\n",
      "0.7649178851346061\n",
      "mean: 0.7899456920920961\n"
     ]
    }
   ],
   "source": [
    "auc_l = []\n",
    "for train_index, test_index in SKF.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    X_train2, X_valid, y_train2, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "    lgb_train = lgb.Dataset(X_train2, y_train2)\n",
    "    lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
    "    LGB = lgb.train(lgbm_params, lgb_train,\n",
    "                    # モデルの評価用データを渡す\n",
    "                    valid_sets=lgb_eval,\n",
    "                    # 最大で 1000 ラウンドまで学習する\n",
    "                    num_boost_round=1000,\n",
    "                    # 10 ラウンド経過しても性能が向上しないときは学習を打ち切る\n",
    "                    early_stopping_rounds=10,\n",
    "                    # うるさいので黙らせる\n",
    "                    verbose_eval = False)\n",
    "    y_pred = LGB.predict(X_test, num_iteration=LGB.best_iteration)\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    print(auc)\n",
    "    auc_l.append(auc)\n",
    "print('mean: {}'.format(mean(auc_l)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=1729)\n",
    "sss.get_n_splits(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7857756014498638\n",
      "0.7808714945798012\n",
      "0.7851930691073468\n",
      "0.7919553475543327\n",
      "0.7772772668742753\n",
      "0.7905908421114124\n",
      "0.7798869188754509\n",
      "0.7963503296615326\n",
      "0.7848703260026689\n",
      "0.7736988805643239\n",
      "mean: 0.7846470076781009\n"
     ]
    }
   ],
   "source": [
    "auc_l = []\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    X_train2, X_valid, y_train2, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "    lgb_train = lgb.Dataset(X_train2, y_train2)\n",
    "    lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
    "    LGB = lgb.train(lgbm_params, lgb_train,\n",
    "                    # モデルの評価用データを渡す\n",
    "                    valid_sets=lgb_eval,\n",
    "                    # 最大で 1000 ラウンドまで学習する\n",
    "                    num_boost_round=1000,\n",
    "                    # 10 ラウンド経過しても性能が向上しないときは学習を打ち切る\n",
    "                    early_stopping_rounds=10,\n",
    "                    # うるさいので黙らせる\n",
    "                    verbose_eval = False)\n",
    "    y_pred = LGB.predict(X_test, num_iteration=LGB.best_iteration)\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    print(auc)\n",
    "    auc_l.append(auc)\n",
    "print('mean: {}'.format(mean(auc_l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sss = 3\n",
    "# mean: 0.7839467217123373\n",
    "# sss = 10\n",
    "# mean: 0.7846470076781009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
